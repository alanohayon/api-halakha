import logging
import tempfile
from fastapi import APIRouter, Depends, File, HTTPException, BackgroundTasks, UploadFile, status, Form
from typing import List, Dict, Any, Optional
import uuid
from supabase import Client
import os
from datetime import datetime

# Imports core
from app.core.config import Settings, get_settings
from app.core.database import get_supabase

# Imports services
from app.services.processing_service import ProcessingService
from app.services.supabase_service import SupabaseService

# Imports schemas
from app.schemas.halakha import (
    HalakhaInputBrut,
    HalakhaNotionPost,
)

# Imports utilitaires
from app.utils.validators import sanitize_json_text

# Imports schemas additionnels
from app.schemas.halakha import HalakhaNotionPost

# ============================================================================
# D√âPENDANCES OPTIMIS√âES POUR LA PRODUCTION
# ============================================================================

def get_supabase_service() -> SupabaseService:
    """D√©pendance pour SupabaseService optimis√©e"""
    return SupabaseService()

def get_processing_service() -> ProcessingService:
    """D√©pendance pour ProcessingService optimis√©e"""
    return ProcessingService()

router = APIRouter()
logger = logging.getLogger(__name__)

@router.post("/halakhot/post", response_model=HalakhaNotionPost)
async def process_halakha_to_notion(
    content: str = Form(..., min_length=10, max_length=10000, description="Contenu de la halakha √† traiter"),
    schedule_days: int = Form(
        default=0, 
        ge=0, 
        le=100, 
        description="Nombre de jours de report pour la programmation (0-100 uniquement)",
        example=7
    ),
    last_img: bool = Form(
        default=False,
        description="Si True, sauvegarde la derni√®re image dans Supabase puis dans notion"
    ),
    processing_service: ProcessingService = Depends(get_processing_service)
):
    """
    Traite une halakha avec OpenAI et la publie sur Notion.
    
    Args:
        content: Le texte complet de la halakha √† analyser
        schedule_days: Nombre de jours √† ajouter pour la date de publication (0-100)
        
    Returns:
        HalakhaNotionPost: R√©ponse contenant l'URL de la page Notion cr√©√©e
        
    Raises:
        HTTPException: Si erreur lors du traitement
    """
    logger.info(f"üîÑ Requ√™te re√ßue pour traiter une halakha vers Notion")
    
    # Validation stricte du contenu
    if not content or not content.strip():
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail="Le contenu de la halakha ne peut pas √™tre vide"
        )
    
    if schedule_days < 0 or schedule_days > 100:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail="schedule_days doit √™tre entre 0 et 100 inclus"
        )
    
    logger.info(f"‚úÖ Param√®tres valid√©s - Contenu: {len(content.strip())} caract√®res, Jours: {schedule_days}")
    
    try:
        # Nettoyer le contenu textuel
        sanitized_content = sanitize_json_text(content.strip())
        
        # Lancer le processus complet via ProcessingService (avec sauvegarde Supabase)
        notion_url = await processing_service.process_halakha_complete(
            halakha_content=sanitized_content,
            add_day_for_notion=schedule_days,
            last_image=last_img  # Save la derniere image dans supabase puis dans notion
        )
        
        logger.info(f"‚úÖ Halakha trait√©e avec succ√®s. URL Notion: {notion_url}")
        
        return HalakhaNotionPost(notion_page_url=notion_url)

    except Exception as e:
        logger.error(f"‚ùå Erreur lors du traitement halakha vers Notion: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Une erreur interne est survenue: {str(e)}"
        )
        
        
@router.post("/batch/halakhot", status_code=status.HTTP_201_CREATED)
async def process_halakhot_from_json(
    start_index: int = Form(
        default=0, 
        ge=0, 
        description="Index de d√©part dans le fichier JSON des halakhot (commence √† 0)",
        example=0
    ),
    limit_halakhot: int = Form(
        default=10, 
        ge=1, 
        le=50, 
        description="Nombre maximum d'halakhot √† traiter (1-50)",
        example=10
    ),
    schedule_days: int = Form(
        default=0, 
        ge=0, 
        le=365, 
        description="Nombre de jours de d√©calage pour la premi√®re halakha (0-365)",
        example=0
    ),
    max_retries: int = Form(
        default=3, 
        ge=0, 
        le=10, 
        description="Nombre maximum de tentatives par halakha (0-10)",
        example=3
    ),
    fail_fast_on_max_retries: bool = Form(
        default=True, 
        description="Si True, arr√™te le batch en cas d'√©chec d√©finitif d'une halakha"
    ),
    processing_service: ProcessingService = Depends(get_processing_service)
):
    """
    üöÄ Traite plusieurs halakhot en lot depuis le fichier JSON vers Notion
    
    Args:
        start_index: Index de d√©part dans le fichier JSON (0-based)
        limit_halakhot: Nombre maximum d'halakhot √† traiter (1-50)
        schedule_days: Jours de d√©calage pour la premi√®re halakha (auto-incr√©ment√©)
        max_retries: Nombre maximum de tentatives par halakha
        fail_fast_on_max_retries: Arr√™t du batch si √©chec d√©finitif
        
    Returns:
        Rapport d√©taill√© du traitement en lot avec statistiques
        
    Raises:
        HTTPException: Si erreur de validation ou traitement
    """
    logger.info(f"üöÄ D√©marrage batch processing - Range: {start_index}-{start_index + limit_halakhot - 1}")
    logger.info(f"üìã Param√®tres: schedule_days={schedule_days}, max_retries={max_retries}, fail_fast={fail_fast_on_max_retries}")
    
    # Validation des param√®tres
    if limit_halakhot > 50:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail="limit_halakhot ne peut pas d√©passer 50 pour √©viter les timeouts"
        )
    
    if schedule_days > 365:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail="schedule_days ne peut pas d√©passer 365 jours"
        )
    
    try:
        # Lancer le traitement en lot via ProcessingService
        batch_result = await processing_service.process_halakhot_from_json(
            start_index=start_index,
            schedule_days=schedule_days,
            limit_halakhot=limit_halakhot,
            max_retries=max_retries,
            fail_fast_on_max_retries=fail_fast_on_max_retries
        )
    # D√©terminer le statut HTTP selon le r√©sultat
        if batch_result["status"] == "failed_fast":
            # Fail-fast d√©clench√© - retourner 207 Multi-Status
            status_code = status.HTTP_207_MULTI_STATUS
            message = f"Batch arr√™t√© en fail-fast √† la halakha #{batch_result.get('fail_fast_triggered_at_index', 'N/A')}"
        elif batch_result["failed_count"] > 0:
            # Succ√®s partiel - retourner 207 Multi-Status  
            status_code = status.HTTP_207_MULTI_STATUS
            message = f"Batch compl√©t√© avec {batch_result['failed_count']} √©chec(s) sur {batch_result['processed_count']}"
        else:
            # Succ√®s complet - retourner 200 OK
            status_code = status.HTTP_200_OK
            message = f"Batch compl√©t√© avec succ√®s - {batch_result['success_count']} halakhot trait√©es"
        
        logger.info(f"‚úÖ {message}")
        
        # Retourner la r√©ponse enrichie
        return {
            "status": "success" if batch_result["failed_count"] == 0 else "partial_success",
            "message": message,
            "data": batch_result,
            "summary": {
                "total_processed": batch_result["processed_count"],
                "successful": batch_result["success_count"],
                "failed": batch_result["failed_count"],
                "skipped": batch_result.get("skipped_count", 0),
                "success_rate": batch_result["success_rate"],
                "range": f"{batch_result['start_index']}-{batch_result.get('end_index', 'N/A')}",
                "fail_fast_triggered": batch_result["status"] == "failed_fast"
            }
        }
        
    except RuntimeError as e:
        # Erreur fail-fast ou critique
        if "fail-fast" in str(e):
            logger.error(f"üö® Fail-fast d√©clench√©: {e}")
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail=f"Traitement arr√™t√© en mode fail-fast: {str(e)}"
            )
        else:
            logger.error(f"‚ùå Erreur critique du batch: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Erreur critique lors du traitement: {str(e)}"
            )
    
    except ValueError as e:
        # Erreur de validation ou param√®tres invalides
        logger.error(f"‚ùå Erreur de validation: {e}")
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=f"Param√®tres invalides: {str(e)}"
        )
    
    except Exception as e:
        # Erreur inattendue
        logger.error(f"‚ùå Erreur inattendue lors du batch: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Une erreur inattendue est survenue: {str(e)}"
        )

@router.post("/images", status_code=status.HTTP_201_CREATED)
async def upload_image(
    file: UploadFile = File(..., description="Fichier image √† uploader"),
    clean_filename: Optional[str] = Form(None, description="Nom de fichier personnalis√©")
):
    """
    Upload une image vers Supabase Storage et retourne l'URL publique
    
    Args:
        file: Fichier image (.png, .jpg, .jpeg, .webp) √† uploader
        clean_filename: Nom de fichier personnalis√© (optionnel)
        
    Returns:
        dict: R√©ponse contenant l'URL de l'image upload√©e
        
    Raises:
        HTTPException: Si erreur lors de l'upload ou format de fichier invalide
    """
    logger.info(f"Requ√™te re√ßue pour upload d'image : {file.filename}")
    
    # Validation basique du fichier
    if not file.filename:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail="Nom de fichier requis"
        )
    
    # V√©rifier le type de fichier
    allowed_extensions = {".png", ".jpg", ".jpeg", ".webp"}
    file_extension = os.path.splitext(file.filename.lower())[1]
    
    if file_extension not in allowed_extensions:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=f"Format non support√©. Formats accept√©s : {', '.join(allowed_extensions)}"
        )
    
    # V√©rifier le content-type
    allowed_content_types = {"image/png", "image/jpeg", "image/jpg", "image/webp"}
    if file.content_type not in allowed_content_types:
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=f"Type MIME non support√© : {file.content_type}"
        )
    
    # V√©rifier la taille du fichier (max 10MB)
    file_content = await file.read()
    if len(file_content) > 10 * 1024 * 1024:  # 10MB
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail="Fichier trop volumineux (max 10MB)"
        )
    
    logger.info(f"Param√®tres valid√©s - Fichier: {file.filename}, Taille: {len(file_content)} bytes")
    
    try:
        # Instancier le service d'orchestration
        processing_service = ProcessingService()
        
        # Lancer l'upload via le service d'orchestration
        result = await processing_service.upload_image_to_storage(
            file_content=file_content,
            filename=file.filename,
            clean_filename=clean_filename
        )
        
        logger.info(f"‚úÖ Image upload√©e avec succ√®s : {result['filename']}")
        
        return {
            "status": "success", 
            "message": "Image upload√©e avec succ√®s",
            "data": result
        }
        
    except Exception as e:
        logger.error(f"Erreur lors de l'upload d'image : {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Une erreur interne est survenue : {str(e)}"
        )

@router.get("/images/latest")
async def get_latest_image():
    """
    R√©cup√®re l'URL de la derni√®re image upload√©e dans Supabase Storage
    
    Returns:
        dict: R√©ponse contenant l'URL de la derni√®re image
        
    Raises:
        HTTPException: Si aucune image trouv√©e ou erreur
    """
    logger.info("Requ√™te re√ßue pour r√©cup√©rer la derni√®re image")
    
    try:
        # Instancier le service d'orchestration 
        processing_service = ProcessingService()
        
        # R√©cup√©rer la derni√®re image via Supabase service
        image_url, name = await processing_service.supabase_service.get_last_img_supabase()
        
        if not image_url:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Aucune image trouv√©e dans le storage "
            )

        
        return {
            "status": "success",
            "message": "Derni√®re image r√©cup√©r√©e avec succ√®s",
            "data": {
                "image_url": image_url,
                "name": name
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration de la derni√®re image : {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Une erreur interne est survenue : {str(e)}"
        )

